package org.vitrivr.engine.index.exporters

import io.github.oshai.kotlinlogging.KLogger
import io.github.oshai.kotlinlogging.KotlinLogging
import kotlinx.coroutines.CoroutineScope
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.channels.ProducerScope
import kotlinx.coroutines.flow.Flow
import kotlinx.coroutines.flow.onEach
import kotlinx.coroutines.withContext
import org.bytedeco.ffmpeg.global.avcodec
import org.bytedeco.ffmpeg.global.avutil
import org.bytedeco.javacpp.PointerScope
import org.bytedeco.javacv.*
import org.vitrivr.engine.core.context.IndexContext
import org.vitrivr.engine.core.model.content.element.AudioContent
import org.vitrivr.engine.core.model.content.element.ContentElement
import org.vitrivr.engine.core.model.content.element.ImageContent
import org.vitrivr.engine.core.model.retrievable.Retrievable
import org.vitrivr.engine.core.model.retrievable.attributes.SourceAttribute
import org.vitrivr.engine.core.model.retrievable.attributes.time.TimeRangeAttribute
import org.vitrivr.engine.core.operators.Operator
import org.vitrivr.engine.core.operators.general.Exporter
import org.vitrivr.engine.core.operators.general.ExporterFactory
import org.vitrivr.engine.core.source.MediaType
import org.vitrivr.engine.core.source.Metadata
import org.vitrivr.engine.core.source.Source
import org.vitrivr.engine.core.source.file.FileSource
import org.vitrivr.engine.core.source.file.MimeType
import java.awt.image.BufferedImage
import java.awt.image.DataBufferByte
import java.nio.ByteBuffer
import java.nio.file.Files
import java.nio.file.Paths
import java.util.*
import java.util.concurrent.TimeUnit
import kotlin.concurrent.fixedRateTimer


private val logger: KLogger = KotlinLogging.logger {}

/**
 * An [Exporter] that generates for each video segment a cropped video file
 *
 * @author Rahel Arnold
 * @version 2.1.0
 */
class VideoSegmentExporter : ExporterFactory {

    companion object {
        val SUPPORTED = setOf(MimeType.MP4)
    }

    /**
     * Creates a new [Exporter] instance from this [VideoSegmentExporter].
     *
     * @param name The name of the [Exporter]
     * @param input The [Operator] to acting as an input.
     * @param context The [IndexContext] to use.
     */
    override fun newExporter(name: String, input: Operator<Retrievable>, context: IndexContext): Exporter {
        val mimeType =
            context[name, "mimeType"]?.let {
                try {
                    MimeType.valueOf(it.uppercase())
                } catch (e: java.lang.IllegalArgumentException) {
                    null
                }
            } ?: MimeType.MP4
        val location =
            context[name, "location"]?.let { it.lowercase() } ?: throw IllegalArgumentException("No location specified")
        val video = context[name, "video"]?.let { it.lowercase() == "true" } ?: true
        val audio = context[name, "audio"]?.let { it.lowercase() == "true" } ?: true
        val useGrabber = context[name, "useGrabber"]?.let { it.lowercase() == "true" } ?: false
        val keyFrames = context[name, "keyFrames"]?.let { it.lowercase() == "true" } ?: false
        logger.debug {
            "Creating new VideoSegmentExporter with mimeType=$mimeType."
        }
        return Instance(input, context, mimeType, location, video, audio, keyFrames, name, useGrabber)
    }


    /** The [Exporter] generated by this [VideoSegmentExporter]. */
    private class Instance(
        override val input: Operator<Retrievable>,
        private val context: IndexContext,
        private val mimeType: MimeType,
        private val location: String,
        private val video: Boolean = true,
        private val audio: Boolean = true,
        private val keyFrames: Boolean = false,
        override val name: String,
        private val useGrabber: Boolean? = false
    ) : Exporter {

        private var grabber: Pair<FFmpegFrameGrabber, UUID>? = null

        init {
            require(mimeType in SUPPORTED) {
                "VideoPreviewExporter only supports image formats JPEG and PNG."
            }
        }

        override fun toFlow(scope: CoroutineScope): Flow<Retrievable> = this.input.toFlow(scope).onEach { retrievable ->

            val source = retrievable.filteredAttribute(SourceAttribute::class.java)?.source ?: return@onEach

            if (source.type != MediaType.VIDEO || retrievable.type != "SEGMENT") {
                logger.debug { "In flow: Skipping source ${source.name} (${source.sourceId}) because it is not of type VIDEO." }
                return@onEach
            }

            val startTimestamp = retrievable.filteredAttribute(TimeRangeAttribute::class.java)?.startNs!! / 1000
            val endTimestamp = retrievable.filteredAttribute(TimeRangeAttribute::class.java)?.endNs!! / 1000
            val resolvable = this.context.resolver.resolve(retrievable.id, this.mimeType.fileExtension)!!
            val path = "$location/${retrievable.id}/segment.${this.mimeType.fileExtension}"

            if (source is FileSource && useGrabber == true) {
                if (this.grabber == null) {
                    this.grabber = Pair(FFmpegFrameGrabber(source.path.toFile()), source.sourceId)
                }
                if (this.grabber?.second != source.sourceId) {
                    this.grabber?.first?.release()
                    this.grabber?.first?.close()
                    this.grabber = Pair(FFmpegFrameGrabber(source.path.toFile()), source.sourceId)
                }
                decodeFromGrabber(source, this.grabber!!.first, path, startTimestamp, endTimestamp)
            } else {
                decode(source, retrievable.content, path, startTimestamp, endTimestamp)
            }
        }


        /**
         * Decodes a video from a [FFmpegFrameGrabber] and emits [Retrievable] elements to the downstream [channel].
         *
         * @param source The [Source] from which the video is being decoded.
         * @param grabber The [FFmpegFrameGrabber] used to decode the video.
         * @param channel The [ProducerScope] used to emit [Retrievable] elements.
         */
        private suspend fun decode(
            source: Source,
            content: List<ContentElement<*>>,
            path: String,
            startMs: Long,
            endMs: Long,
        ) {

            logger.info { "Start recording segment from ${startMs / 1000000} to ${endMs / 1000000} of source ${source.name} (${source.sourceId})" }


            withContext(Dispatchers.IO) {
                Files.createDirectories(Paths.get(path).parent)
            }

            val recorder = FFmpegFrameRecorder(
                path,
                source.metadata[Metadata.METADATA_KEY_IMAGE_WIDTH]!! as Int, //grabber.imageWidth,
                source.metadata[Metadata.METADATA_KEY_IMAGE_HEIGHT]!! as Int, //grabber.imageHeight,
                source.metadata[Metadata.METADATA_KEY_AUDIO_CHANNELS]!! as Int //grabber.audioChannels
            )
            try {
                recorder.start()
                configureRecorder(recorder, source)

                for (c in content) {

                    when (c) {
                        is ImageContent -> {
                            val f = Frame(c.content.width, c.content.height, 8, 4)
                            val frame = createFrame(c.content, f)
                            try {
                                PointerScope().use { scope -> recorder.record(frame) }
                            } catch (e: Exception) {
                                logger.error(e) { "Error converting frame to BufferedImage" }
                            }
                        }

                        is AudioContent -> {
                            logger.warn { "Audio content found. Audio recording not yet implemented." }
                        }

                        else -> { /* No op. */
                        }
                    }
                }
            } catch (e: Exception) {
                logger.error(e) { "Error while recording video segment. ${e.cause.toString()}" }
            } finally {
                recorder.flush()
                recorder.stop()
                recorder.close()
            }
            logger.info { "Finished decoding video from source '${source.name}' (${source.sourceId}):" }
        }

        private fun createFrame(image: BufferedImage, frame: Frame?): Frame {
            var frame = frame
            val imageBuffer = image.raster.dataBuffer as DataBufferByte
            val stride = imageBuffer.data.size / image.height

            if (frame == null || frame.imageWidth !== image.width || frame.imageHeight !== image.height) frame =
                Frame(image.width, image.height, 8, 4)

            val frameBuffer: ByteBuffer = frame.image[0].position(0) as ByteBuffer

            frameBuffer.put((image.raster.dataBuffer as DataBufferByte).data)
            frameBuffer.position(0)

            return frame
        }


        /**
         * Decodes a video from a [FFmpegFrameGrabber] and emits [Retrievable] elements to the downstream [channel].
         *
         * @param source The [Source] from which the video is being decoded.
         * @param grabber The [FFmpegFrameGrabber] used to decode the video.
         * @param channel The [ProducerScope] used to emit [Retrievable] elements.
         */
        private suspend fun decodeFromGrabber(
            source: Source,
            grabber: FFmpegFrameGrabber,
            path: String,
            startMs: Long,
            endMs: Long,
        ) {
            /* Configure FFmpegFrameGrabber. */
            grabber.imageMode = FrameGrabber.ImageMode.COLOR
            grabber.sampleMode = FrameGrabber.SampleMode.SHORT


            logger.info { "Start recording segment from ${startMs / 1000000} to ${endMs / 1000000} of source ${source.name} (${source.sourceId})" }
            try {
                grabber.start()
                grabber.setTimestamp(startMs)
                /* Extract and enrich source metadata. */
                source.metadata[Metadata.METADATA_KEY_VIDEO_FPS] = grabber.videoFrameRate
                source.metadata[Metadata.METADATA_KEY_AV_DURATION] =
                    TimeUnit.MICROSECONDS.toMillis(grabber.lengthInTime)
                source.metadata[Metadata.METADATA_KEY_IMAGE_WIDTH] = grabber.imageWidth
                source.metadata[Metadata.METADATA_KEY_IMAGE_HEIGHT] = grabber.imageHeight
                source.metadata[Metadata.METADATA_KEY_AUDIO_CHANNELS] = grabber.audioChannels
                source.metadata[Metadata.METADATA_KEY_AUDIO_SAMPLERATE] = grabber.sampleRate
                source.metadata[Metadata.METADATA_KEY_AUDIO_SAMPLESIZE] = grabber.sampleFormat

                withContext(Dispatchers.IO) {
                    Files.createDirectories(Paths.get(path).parent)
                }

                val recorder = FFmpegFrameRecorder(
                    path,
                    grabber.imageWidth,
                    grabber.imageHeight,
                    grabber.audioChannels
                )
                try {
                    recorder.start()
                    configureRecorder(recorder, source)

                    do {
                        val frame =
                            grabber.grabFrame(
                                this@Instance.audio,
                                this@Instance.video,
                                true,
                                this@Instance.keyFrames,
                                true
                            ) ?: break

                        if (grabber.timestamp >= endMs) {
                            break
                        }

                        when (frame.type) {
                            Frame.Type.VIDEO -> {
                                try {
                                    PointerScope().use { scope -> recorder.record(frame) }
                                } catch (e: Exception) {
                                    logger.error(e) { "Error converting frame to BufferedImage" }
                                }
                            }

                            Frame.Type.AUDIO -> {
                                try {
                                    PointerScope().use { scope -> recorder.record(frame) }
                                } catch (e: Exception) {
                                    logger.error(e) { "Error converting frame to BufferedImage" }
                                }
                            }

                            else -> { /* No op. */
                            }
                        }
                    } while (true)
                } catch (e: Exception) {
                    logger.error(e) { "Error while recording video segment. ${e.cause.toString()}" }
                } finally {
                    recorder.flush()
                    recorder.stop()
                    recorder.close()
                }
                logger.info { "Finished decoding video from source '${source.name}' (${source.sourceId}):" }
            } catch (exception: Exception) {
                logger.error(exception) { "Failed to decode video from source '${source.name}' (${source.sourceId})." }
            } finally {
                grabber.stop()
            }
        }

        /**
         * Configures the [FFmpegFrameRecorder] with the given [FFmpegFrameGrabber]
         **/
        private fun configureRecorder(recorder: FFmpegFrameRecorder, source: Source) {
            recorder.format = "mp4"
            recorder.frameRate = source.metadata[Metadata.METADATA_KEY_VIDEO_FPS] as Double
            recorder.videoBitrate = source.metadata[Metadata.METADATA_KEY_VIDEO_BITRATE] as Int
            recorder.videoCodec = avcodec.AV_CODEC_ID_H264
            recorder.pixelFormat = avutil.AV_PIX_FMT_YUV420P
            recorder.audioCodec = avcodec.AV_CODEC_ID_AAC
            recorder.audioChannels = source.metadata[Metadata.METADATA_KEY_AUDIO_CHANNELS] as Int
            recorder.sampleRate = source.metadata[Metadata.METADATA_KEY_AUDIO_SAMPLERATE] as Int
            recorder.audioBitrate = source.metadata[Metadata.METADATA_KEY_AUDIO_BITRATE] as Int
        }
    }
}